
Assignment 5 Thor Olesen, Nicoline Scheel, Dennis Nguyen 

Exercise 5.1.1: See exercise511.txt

Exercise 5.1.2: See exercise512.txt 

Exercise 5.1.3: See exercise513.png 

Exercise 5.1.4: See exercise514reflection.png for a graph comparing task,threads and time/performance
It may be seen that using a CachedThreadPool utilizing tasks performs better than using explicit threads.
A possible explanation may be that the CachedThreadPool does not initialize a new thread each time a task has to be performed. 
Rather, it reuses threads, and therefore does not incur the overhead of thread initilization and teardown as often, therefore amortizing
the cost of thread creation and teardown.
Finally, the gain in performance is significant between 1-4 threads/tasks but is minimal from 5+ threads/tasks. 
This is due to the fact that the number of physical cores available on the computer that we ran the computation on is 4.

Exercise 5.1.5: See exercise 515.txt where LongCounter has been replaced with LongAdder 

Based on the data, the LongAdder version performs slightly better overall than using the LongCounter in a CachedThreadPool. 

Seemingly, the LongAdder variable is rarely inspected (only once in the final return statement).
Thus, it is only added to frequently by the tasks and performs well. 

Exercise 5.2 : Optional (has not been made) 

Exercise 5.3.1: Code example works and fetches wikipedia HTML 

Exercise 5.3.2: See TestDownload.java and getPages() implementation  

Exercise 5.3.3: See TestDownload.java main method 
1st measurement: 2.011867124
2nd measurement: 3.294948529 
3rd measurement: 3.114493151
4th measurement: 6.141582393
5th measurement: 3.257741176

Exercise 5.3.4: See TestDownload.java method getPagesParallelo.
1st measurement: 1.361790646
2nd measurement: 1.334920331
3rd measurement: 1.652784479
4th measurement: 2.239112435
5th measurement: 1.30542594

As you can see, this version fetches HTML in parallel and the time is significantly reduced compared to the sequential version.

Why is fetching 23 webpages in parallel not 23 times faster than fetching them one by one?
Presumably, this is because the machine only has 4 cores and the potential of parallelism cannot exceed this. 

Exercise 5.4.1: It ran as expected 

Exercise 5.4.2: see Uniquifier<T> and runAsThreadsUniquifier() in TestPipeline.java 

Exercise 5.4.3: ExecutorService vs threads - see TestPipeline.java

The results should be the same as when using threads. Are they?

The result seems similar to the thread version based on inspection. 

Exercise 5.4.4: FixedThreadPool of size 6 tested in TestPipeline.java

Exercise 5.4.5: FixedThreadPool of size 3 in TestPipeline.java

This probably does not work. What so you observe? Can you explain why?

The program stalls because the thread pool is fixed with 3 threads but 5 tasks are executed concurrently.
These tasks all wait for each other and run in and endless while loop. 
To back this up, we tried running the program with a pool of 5 threads, which worked. 
As soon as we went below this (4 threads for 5 tasks), the program stalls   , presumably because all threads were occupied by 4 tasks that run  on an endless loop (while (true)). 

Exercise 5.4.6 : Two PageGetter objects in runWithMultiplePageGetters() in TestPipeline.java  

Implement this idea. You should get the same results as before, though possibly in a different order. Do you? Why?

Actually, we do not get it in a different order and we do not quite know why?

Intuitively, we would not believe that the PageGetters are "synchronized" (i.e. coordinate with each other),
but maybe the BlockingQueue ensures that the order is maintained on the pipeline. 

Exercise 5.4.7 (OPTIONAL): Implement BoundedQueue<T> 

Explain why your bounded blocking queue works and why it is thread-safe.